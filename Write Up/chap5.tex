\chapter{Methods \& Procedures} \label{sec:sectionFive}

\section{System Overview} \label{sec:systemOverview}

Despite the fact that two rather different algorithms will be used the system is designed to operate more or less the same by implementing the genetic algorithm and support vector machine components as loosely coupled modules to avoid having to redesign the system completely.  Web requests will be processed through a parser that searches for various aspects related to each of the three possible web attacks.  These results become output and can be used as input for either the genetic algorithm, support vector machine, or potentially another algorithm that could extend the research even further.  Finally, the machine learning modules will output the results to a file that can be processed by graphing tools (Figure \ref{fig:sys}), in this case the R programming language will be used to create graphs of the results that can be used to drawn conclusions on the two approaches.

\begin{figure}
	\label{fig:sys}
	\includegraphics[width=450px]{./assets/img/system.png}
	\caption{Overview of the system}
\end{figure}

\section{Gathering Test Data} \label{sec:gatheringTestData}

All data will be gathered from as close to a real-world scenario as possible and in order to do so, automated enumeration exploiting tools will be used to gather a large sample size of varied attacks (Table \ref{tab:tools}).  In order to gather SQL injection attacks the popular tool \textit{sqlmap} will be used, for XSS attacks \textit{grabber} and \textit{xsser} will be used.

\begin{table}
	\begin{tabular}{|l|l|}
	\hline
		\textbf{Request Type} & \textbf{Generation Method}\\
	\hhline{|=|=|}
		SQL Injection & sqlmap \cite{sqlmap} \\
	\hline
		XSS Attack & grabber \cite{grabber}, xsser \cite{xsser} \\
	\hline
		RFI Attack & randomized generation \\
	\hline
		Normal Requests & httpfox \cite{httpfox} \\
	\hline
	\end{tabular}
	\caption{Breakdown of test data generation}
	\label{tab:tools}
\end{table}

These tools will be let loose on a private apache web-server that is hosting a very simple database connected application.  However for gathering a large amount of RFI attacks it will require generation of a large sample size as the tooling for these types of attacks is rather limited and the tools that do exist do not perform large scale enumeration attacks and instead attempt to compromise the server as fast as possible. \cite{fimap}  Because RFI attacks are the simpliest in terms of their design and variations, a simple automated Python script can be used to generate a large amount of attacks using a heavy amount of randomization.  Finally, it is nessecary to also include some normal web requests which are not attacks to test for false positives.  This can easily be done by using the application as well as other websites normally, submitting form inputs, etc, and collecting all of the resulting HTTP requests.  This will be done with a simple browser extension for Mozilla Firefox, HTTPFox.

Like most web-servers, Apache has the ability to log all of the requests that it serves to a file.  The data that we need to parse for the genetic algorithm and support vector machine is the GET or POST HTTP request line. Therefore the final step of gathering the testing and training data is to compile the log files and strip out all unneeded information so it can be passed to the parser.  Another small Python script will be used to generate a test file of the correct size and proportions using these large banks of requests.  The script will generate a file where each line contains the request line content and what type the request is, either SQLi, XSS, RFI, or not an attack this labels the data for supervised learning and performance evaluations.

\section{Parsing the Requests} \label{sec:methodsParser}

With the completed test file(s) containing the proper amount of each attack and normal requests, the next step is to parse each request into numeric values so that the algorithms can work with them.  Each request has their own respective features that are worth identifying, with the genetic algorithm requiring more features to be identified than for the SVM.  These features have been identified for each request type by previous research (Table \ref{tab:features}) but is important to distinguish what the meaning of each is, as well as what can and cannot be parsed. \cite{mainPaper}

\begin{table}
	\centering
	\begin{tabular}{|p{1.5in}|p{4.5in}|}
	\hline
		\textbf{Request Type} & \textbf{Features}\\
	\hhline{|=|=|}
		SQL Injection & \# SQL keywords, is encoded, \# fields containing SQL keyword, attack variant\\
	\hline
		XSS Attack & \# of HTML or JavaScript keywords, is encoded, \# fields containing a HTML or javascript keyword, attack variant\\
	\hline
		RFI Attack & \# of URLs, is encoded, \# of commands, attack variant\\
	\hline
	\end{tabular}
	\caption{Parseable Features}
	\label{tab:features}
\end{table}

The number of SQL keywords or reserved words is obtained by using comprehensive lists obtained from the Oracle and MySQL DBMS documentation.\cite{oracle}\cite{mysql}  This works well with our test environment as well, as the DBMS our application is using is MySQL and many of the automated tools will use MySQL specific vulnerabilities.  Similarly, the HTML and JavaScript keywords were obtained from the official W3C documentation\cite{w3c1}\cite{w3c2}\cite{w3c3} as well as the PHP related commands were sourced from the PHP documentation.\cite{php}

Requests are also capable of being encoded as well to further evade detection (Section \ref{sec:sectionTwo}) which is something that can be easily detected and recorded.  HTTP requests, usually GET requests specifically, will contain fields and information that the request carries to the application code.  This information can be user supplied information (ex. a username or password) or application supplied information (ex. the current page number), either way it is able to be directly modified by a user and is where injections and malicious code is likely to lie (Figure \ref{fig:sampleRequest}).  For this reason, it is good to make a distinction between just a total number of keywords found and the number of fields that actually contain keywords to get a more complete picture of the request.  Lastly, all of the discussed attack variants (Section \ref{sec:sectionTwo}) can be detected with the exception of \emph{Stored Procedure SQL injections}, which brings up the limitations of this type of parsing (Section \ref{sec:disadvantagesParsing}).

\begin{figure}
	\centering
	\code{https://duckduckgo.com/?\hl{q=HTTP+Request}\&\hl{t=vivaldi}\&\hl{ia=web}}
	\caption{A sample HTTP request with fields highlighted}
	\label{fig:sampleRequest}
\end{figure}

The parser makes heavy use of regular expressions (Appendix \ref{app:regex}) to determine much of this information such as the keywords or contents of the fields and is designed to overcome common evasion tactics.  One such tactic is padding the alternate encodings of the request, instead of using the common two byte hexadecimal conversion of the ASCII values, several zeros can be appended to the two bytes to confuse simple parsers using built-in decoding libraries.  Another issue that had to be overcame was not double-counting keywords that were a prefix to another keyword, which is done simply by associating each word with its prefix combinations.  This results in only a minor amount of extra computation as there is not many keywords with prefixes.

\begin{algorithm}[H]
	\setstretch{1.0}
	\caption{General overview of parsing procedure}
	\label{alg:parsing}
	
	\KwData{File with HTTP Requests and their true type}
	\KwResult{Resulting test file with every request stored along with the parsed features for the three types of web threats in the following order: Original $\rightarrow$ SQLi $\rightarrow$ XSS $\rightarrow$ RFI}
	
	read in input file\;
	\For{line in input file}{
	
		\If{SVM testing}{
			disregard encoding and attack variant features\;
		}
		pass request to each parsing module (sql, xss, and rfi)\;
		store original request and type in resulting file\;
		\For{each parsed result}{
			\eIf{for genetic algorithm}{
				
				\eIf{lengths of segment 1 and 3 should be permuted for length testing}{
					\For{each segment length combination up to specified maximum}{
						convert result to binary based on the maximum lengths of each segment\;
						\If{decimal value exceeds maximum value in segment}{
							use maximum allowed value in segment\;
						}
						store result in a list\;
					}
					store complete list on a new line\;
				}{
				convert result to binary based on the maximum lengths of each segment\;
					\If{decimal value exceeds maximum value in segment}{
						use maximum allowed value in segment\;
					}
				store complete bitstring in file on new line\;
				}
			}{
			store decimal values into file on new line\;
			}
		}
	}	
\end{algorithm}

Full documentation on the usage of the parser (Appendix \ref{app:parserDocumentation}).

\section{Genetic Algorithm Based Signature Detection}\label{sec:genIntro}

The method of the using a genetic algorithm for signature based detection is largely the same as the proposed system from previous research with a few modifications. \cite{mainPaper}  One major difference is that instead of allowing the signatures to change to different attack type signatures (ex. SQLi to XSS) the type of attack we want to search for is specified and the algorithm uses the respective parsed result from every request.  This of course requires every original request to be parsed three times instead of just once, but it makes the most sense as if it is possible to transition between attack types so easily then there is no reason to differentiate between them in the first place.  This also allows later results and subsequent conclusions to not be influenced by other factors that can not be measured.  If signatures were allowed to switch to different attacks types then it would be unknown if the results were due to the random nature of a genetic algorithm causing signatures of the wrong type to be chosen or the other variables in question being changed.  

The second major difference is that the bitstring length for each signature is increased to avoid problems of exceeding the quantity in a segment.  In the previous research only 3 bits were used for the segments that count the number of segments or fields in the requests which only allows for a count up to 7.  In a real world setting the amounts for the number of fields and keywords can be much much larger and exceeding these values often creates a situation where there are many signatures that match which normally would not.  For example, if two signatures have 10 and 11 keywords respectively, with the old segment lengths they would be capped at 7  (111 in binary), resulting in a match which should not have occured.  Therefore these segment lengths with a size problem have been extended to 6 bits allowing for counts up to 63 (Table \ref{tab:geneticSegments}).

\begin{table}
	\begin{tabular}{|p{1.25in}|p{1in}|p{1in}|p{1in}|p{1in}|}
	\hline
	\multicolumn{1}{|p{1.25in}|}{\textbf{Request Type}} & \multicolumn{4}{p{4in}|}{\textbf{Segment Information}} \\ \hhline{|=|=|=|=|=|}
	\multirow{2}{*}{\textbf{SQL Injection}}            & \# of SQL Keywords & is encoded & \# of fields containing a SQL keyword & attack variant \\ \cline{2-5} 
		                                      & 6             & 1          & 6            & 3 \\ \hline  
	\multirow{2}{*}{\textbf{XSS Attack}}               & \# of HTML or javascript keywords & is encoded & \# of fields containing a HTML or javascript keyword & attack variant \\ \cline{2-5} 
		                                      & 6             & 1          & 6            & 3 \\ \hline
	\multirow{2}{*}{\textbf{RFI Attack}}               & \# of URLs & is encoded & \# of PHP commands & attack variant \\ \cline{2-5} 
		                                      & 6             & 1          & 6            & 3 \\ \hline  
	\end{tabular}
	\caption{Genetic algorithm default segment breakdown}
	\label{tab:geneticSegments}
\end{table}

The genetic algorithm implementation is very standard, allowing for the following parameters to be changed (Appendix \ref{app:geneticDocumentation}):

\begin{itemize}
	\setstretch{1.0}
	\item Maximum population per generation
	\item Maximum number of generations
	\item Mutation rate
	\item Elitist selection amount
\end{itemize}

Most of the genetic operators are fairly simplistic to implement with the most complex being the selection algorithm.  The higher the fitness of the individual the more likely it will be selected by the selection algorithm to be crossed over.  There are several ways for the selection algorithm to be implemented but for this research Roulette Wheel Selection, also referred to as Fitness Proportionate Selection, will be used (Algorithm \ref{alg:selection}).  This algorithm was chosen because the proposed genetic algorithm technique from existing research was fitness based\cite{mainPaper}, not reward based like some other selection algorithms.  In addition to it being very simple and practical to implement and understand considering the scope of the research.

\begin{algorithm}[H]
	\setstretch{1.0}
	\caption{Basic pseudocode algorithm for Roulette Wheel Selection in \BigO{n}}
	\label{alg:selection}
	\KwData{Fitness values of all individuals in population}
	\KwResult{The selected individual}
	
	$totalWeight = 0$\;
	\For{all individuals weights}{
		$totalWeight = totalWeight + weight$\;
	}
	
	$rand = a random number between 0 and the totalWeight$\;
	\For{all individuals weights}{
		
		$rand = rand - weight$\;
		\If{$rand < 0$}{
			return that individual's index\;
		}
	}
	
	\If{Unable to find an individual}{
		error occured, fall back condition is to return the last item\;
	}
\end{algorithm}

The genetic algorithm was written from scratch using the Python programming language and is designed to handle input files produced by the parser containing lines of single bitstrings or with several variations of the segment lengths (Algorithm \ref{alg:genetic}).

\begin{algorithm}[H]
	\setstretch{1.0}
	\caption{Pseudocode algorithm for genetic algorithm}
	\label{alg:genetic}
	\KwData{Bitstrings for training and testing and all parameters for genetic algorithm}
	\KwResult{The optimized bitstrings that can be used for detection}
	
	\For{each bitstring of varying segment length}{
	
		\For{the number of generations}{
			
			remove duplicate bitstrings in the current population\;
			evaluate fitness for all individuals\;
			
			preserve the top elitist percentage into the new population called the offspring\;
			
			\While{offspring amount $<$ maximum population allowed}{
				
				select two individuals and perform a single point crossover\;
				add these two newly individuals to the next population
			}
			
			trim the offspring to the maximum population\;
			loop through every allele in every offspring with the chance to mutate\;
			set the current population to the offspring
		}
		
		store the bitstring signature results for that length
	}
\end{algorithm}

\subsection{Testing Procedure}

In order to the test the genetic algorithm fairly, both training data and testing data will have equal proportions of all three attacks, 30\% for each attack and then 10\% of non attacks for false positive measurements (Table \ref{tab:trainingfile} \& \ref{tab:testfile}).  In addition, the testing data contains different requests than that used in training as this would be the situation that these approaches would be used in the real world.  They would be trained using supervised learning and then used to identify unlabeled data entering the system, therefore it does not make sense to test with the same data it was trained on.

\begin{table}
	\centering
	\begin{tabular}{|p{1.5in}|p{2.0in}|}
	\hline
		\textbf{Request Type} & \textbf{Number in Sample}\\
	\hhline{|=|=|}
		SQL Injection & 300 \\
	\hline
		XSS Attack & 300 \\
	\hline
		RFI Attack & 300 \\
	\hline
		Non Attacks & 100 \\
	\hhline{|=|=|}
		\textbf{Total} & 1000 \\
	\hline
	\end{tabular}
	\caption{Breakdown of the training file for genetic algorithms}
	\label{tab:trainingfile}
\end{table}	
	
\begin{table}
	\centering
	\begin{tabular}{|p{1.5in}|p{2.0in}|}
	\hline
		\textbf{Request Type} & \textbf{Number in Sample}\\
	\hhline{|=|=|}
		SQL Injection & 1500 \\
	\hline
		XSS Attack & 1500 \\
	\hline
		RFI Attack & 1500 \\
	\hline
		Non Attacks & 500 \\
	\hhline{|=|=|}
		\textbf{Total} & 5000 \\
	\hline
	\end{tabular}
	\caption{Breakdown of the testing file for both genetic algorithm and support vector machine}
	\label{tab:testfile}
\end{table}	

Each test of the genetic algorithm will use the same training and testing data, instead the parameters of the genetic algorithm will be altered to observe any difference in the performance.  The genetic algorithm will first be trained which will output bitstrings that will act as signatures that have been optimized for detecting the particular attack type. Those signatures will then finally be used to match with the unseen testing data's bitstring representations it believes are the attacks (Figure \ref{fig:gasys}).

\begin{figure}
	\includegraphics[width=450px]{./assets/img/gasys.png}
	\caption{Overview of the genetic algorithm system}
	\label{fig:gasys}
\end{figure}

In addition to adjusting the various parameters of the genetic algorithm, using multiple iterations of the algorithm to generate a combined signature set will also be tested.  The belief is that with the additional signatures in the detection set the more likely it is to have a signature in order to detect more of the attacks, so this test will see if that is the case as well as if it has any negative side effects.  This is also one of the proported benefits of this technique, that the genetic algorithm can generate additional signatures for detection automatically instead of relying on manually created signatures.  Lastly, testing the performance using different segment lengths of the bitstrings will also be conducted, the reasoning for this goes back to the issue of overflowing a segment (Section \ref{sec:genIntro}).  Smaller segments should be able to detect more attacks as there are fewer possible combinations, making it easier to generate bitstrings that cover a wider range of attack signatures.  In the extreme case, a segment that can only hold a maximum count of 1 would detect anything if it contained a keyword even if the request contained much more than 1, essentially becoming a flag.

\section{Support Vector Machine Detection}

The SVM detection approach will follow a similar process to the genetic algorithm but rather than changing the parameters of the algorithm, the training data will be manipulated instead (Figure \ref{fig:svmsys}).  This is due to the fact that the parameters for the SVM that matter for performance are automatically optimized by using a grid search provided by the same Python library used to implement the SVM, scikit-learn.\cite{scikit-learn}

\begin{figure}
	\includegraphics[width=450px]{./assets/img/svmsys.png}
	\caption{Overview of the support vector machine system}
	\label{fig:svmsys}
\end{figure}

The parameters that are optimized by the grid search are gamma ($\gamma$) and the penalty cost (C), however gamma only makes a difference in the polynomial and RBF kernels.  Support-vector machines use various different kernel methods to determine the seperating hyperplane in the given data, the kernels that will be used from the provided library is a linear, polynomial with degree 3, and RBF.  Every test will be executed using all three kernels to see which kernel is best-suited for the data sets.  

The one major difference between the SVM and genetic algorithm approaches is that the SVM only requires two of the four parsed segments and they can be in normal decimal representation as mutations need not be (Table \ref{tab:svmSegments}).  The reason that the other two segments are not used by the SVM is because they do not vary nearly as much as the other two.  Many attacks and non-attacks could be encoded or not, as well as being the same attack type, so that information is not very descriptive on it's own.  These two values are plotted on a simple X,Y plane which is then passed into the SVM to be trained, so having more than 2 values would make this step more complicated and is unnecessary.  Each of these X,Y pairs are labelled with either as an attack or not an attack in order to facilitate supervised learning (Algorithm \ref{alg:svm}).

\begin{table}
	\begin{tabular}{|p{1.5in}|p{2in}|p{2in}|}
	\hline
	\multicolumn{1}{|c|}{\textbf{Request Type}} & \multicolumn{2}{p{4in}|}{\textbf{Segments}}               \\ \hhline{|=|=|=|}
	\textbf{SQL Injection}                      & \# of SQL Keywords         & \# of fields containing a SQL keyword \\ \hline
	\textbf{XSS Attack}                      & \# of HTML or JavaScript keywords         & \# of fields containing a HTML or JavaScript keyword \\ \hline
	\textbf{RFI Attack}                      & \# of URLs         & \# of PHP commands \\ \hline
	\end{tabular}
	\caption{Genetic algorithm default segment breakdown}
	\label{tab:svmSegments}
\end{table}

\begin{algorithm}[H]
	\setstretch{1.0}
	\caption{Pseudocode algorithm for support vector machine}
	\label{alg:svm}
	\KwData{Segment information for each request}
	\KwResult{A trained SVM classifier that test data can be passed into and results gathered from}
	
	gather all segment information from training set\;
	
	pack into a numpy array\;
	
	\For{each kernel type ('linear', 'polynomial-3', 'rbf')}{
		
		\If{that kernel type has not already had its parameters optimized}{
			optimize using a GridSearch\;
			store the resulting parameters to save time on the next repeat use of the kernel\;
		}
		
		build the svm using scikit-learn and the optimized parameters\;
		train the classifier using the training vectors and targets\;
		
		pass all testing data through the classifier and record results\;
		
		plot the resulting graph for visual purposes\;
		store results of testing\;
	}
\end{algorithm}

\subsection{Testing Procedure}

For the SVM there are several ways that the training data will be adjusted to measure how the performance changes (Figure \ref{fig:svmsys}).  The exact same testing set that was used for the genetic algorithm will be used and for smaller tests the same training data will also be used but once tests require beyond the 1000 request amount, new training data must be added.  The first test case will use the same proportion of 30\% for all three attack types and 10\% for non threats, this test will essentially be a fair comparison between the SVM and the genetic algorithm approaches.  The second test is designed to see if false positives can be reduced by increasing only the amount of non attack requests in the training set between the various tests.  And lastly, seeing if the number of incorrect attack detection can be reduced, incorrect being identifying a request that is an attack but is not the type we are trying to detect, by increasing only the amount of requests containing the type of attacks we are \textbf{not} looking for.
